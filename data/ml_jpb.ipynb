{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from config import password\n",
    "password = password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transportData = \"Refrigerated_Truck_Rates_and_Availability_Full.csv\"\n",
    "AvoTransportData = \"Refrigerated_Truck_Rates_and_Availability_Avo.csv\"\n",
    "avo_data = \"avo_prices.csv\"\n",
    "gas_data = \"gas_prices.csv\"\n",
    "loadweather = \"SanDiegoWeatherData.csv\"\n",
    "bananaprices = \"banana_prices.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "banana_prices_df = pd.read_csv(bananaprices)\n",
    "# banana_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initSDweather_df = pd.read_csv(loadweather)\n",
    "# initSDweather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_transport_df = pd.read_csv(transportData)\n",
    "# initial_transport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_avo_transport_df = pd.read_csv(AvoTransportData)\n",
    "# initial_avo_transport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avo_data_df = pd.read_csv(avo_data)\n",
    "# avo_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_data_df = pd.read_csv(gas_data)\n",
    "# gas_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "tot_transport_columns = [\"Date\", \"Origin\", \"Destination\", \"Distance\", \"Commodity\", \"Week Low\", \"Week High\", \"Midpoint\", \"Rate Per Mile\", \"Availability\"]\n",
    "tot_transport_df = initial_transport_df[tot_transport_columns].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "tot_transport_df = tot_transport_df.rename(columns={\"Date\": \"date\",\n",
    "                                                        \"Origin\": \"origin\",\n",
    "                                                        \"Destination\": \"destination\",\n",
    "                                                       \"Distance\": \"transport_distance\",\n",
    "                                                       \"Commodity\": \"commodity\",\n",
    "                                                       \"Week Low\": \"low_weekly_rate\",\n",
    "                                                       \"Week High\": \"high_weekly_rate\",\n",
    "                                                       \"Midpoint\": \"average_weekly_rate\",\n",
    "                                                       \"Rate Per Mile\": \"avg_rate_per_mile_ratio\",\n",
    "                                                       \"Availability\": \"availability_score\"\n",
    "                                                   })\n",
    "\n",
    "# tot_transport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_transport_df['date'] = pd.to_datetime(tot_transport_df['date'])\n",
    "# tot_transport_df\n",
    "\n",
    "tot_transport_df['date'] = tot_transport_df['date'] - timedelta(days=1)\n",
    "# tot_transport_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "avo_transport_columns = [\"Date\", \"Origin\", \"Destination\", \"Distance\", \"Commodity\", \"Week Low\", \"Week High\", \"Midpoint\", \"Rate Per Mile\", \"Availability\"]\n",
    "avo_transport_df = initial_avo_transport_df[avo_transport_columns].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "avo_transport_df = avo_transport_df.rename(columns={\"Date\": \"date\",\n",
    "                                                        \"Origin\": \"origin\",\n",
    "                                                        \"Destination\": \"destination\",\n",
    "                                                       \"Distance\": \"transport_distance\",\n",
    "                                                       \"Commodity\": \"commodity\",\n",
    "                                                       \"Week Low\": \"low_weekly_rate\",\n",
    "                                                       \"Week High\": \"high_weekly_rate\",\n",
    "                                                       \"Midpoint\": \"average_weekly_rate\",\n",
    "                                                       \"Rate Per Mile\": \"avg_rate_per_mile_ratio\",\n",
    "                                                       \"Availability\": \"availability_score\"\n",
    "                                                   })\n",
    "\n",
    "# avo_transport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avo_transport_df['date'] = pd.to_datetime(avo_transport_df['date'])\n",
    "# avo_transport_df\n",
    "\n",
    "avo_transport_df['date'] = avo_transport_df['date'] - timedelta(days=2)\n",
    "# avo_transport_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avo_transport_df['date'] = avo_transport_df['date'].dt.strftime('%m/%d/%Y')\n",
    "tot_transport_df['date'] = tot_transport_df['date'].dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avo_transport_df.to_csv(\"avo_transport_df.csv\", index=False, header=True)\n",
    "tot_transport_df.to_csv(\"tot_transport_df.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "avo_columns = [\"New Date\", \"AveragePrice\", \"Total Volume\", \"4046\", \"4225\", \"4770\", \"type\", \"year\", \"region\"]\n",
    "avo_transformed_df = avo_data_df[avo_columns].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "avo_transformed_df = avo_transformed_df.rename(columns={\"New Date\": \"date\",\n",
    "                                                        \"AveragePrice\": \"average_price\",\n",
    "                                                        \"Total Volume\": \"total_volume\",\n",
    "                                                       \"4046\": \"small_avocados_sold\",\n",
    "                                                       \"4225\": \"large_avocados_sold\",\n",
    "                                                       \"4770\": \"xl_avocados_sold\",\n",
    "                                                       \"type\": \"type\",\n",
    "                                                       \"year\": \"year\",\n",
    "                                                       \"region\": \"region\"})\n",
    "\n",
    "# avo_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "gas_columns = [\"Date\", \"Gasoline - All Grades\", \"Regular\", \"Midgrade\", \"Premium\", \"Diesel (On-Highway) - All Types\"]\n",
    "gas_transformed_df = gas_data_df[gas_columns].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "gas_transformed_df = gas_transformed_df.rename(columns={\"Date\": \"date\",\n",
    "                                                        \"Gasoline - All Grades\": \"gas_all_grades\",\n",
    "                                                        \"Regular\": \"regular\",\n",
    "                                                        \"Midgrade\": \"midgrade\",\n",
    "                                                        \"Premium\": \"premium\",\n",
    "                                                        \"Diesel (On-Highway) - All Types\": \"diesel\"})\n",
    "\n",
    "# gas_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dates have the same formatting\n",
    "avo_transformed_df['date'] = pd.to_datetime(avo_transformed_df.date)\n",
    "gas_transformed_df['date'] = pd.to_datetime(gas_transformed_df.date)\n",
    "\n",
    "avo_transformed_df['date'] = avo_transformed_df['date'].dt.strftime('%m/%d/%Y')\n",
    "gas_transformed_df['date'] = gas_transformed_df['date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# gas_transformed_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on region and type\n",
    "avo_transformed_df = avo_transformed_df.loc[avo_transformed_df['region'] == 'TotalUS']\n",
    "avo_transformed_df = avo_transformed_df.loc[avo_transformed_df['type'] == 'conventional']\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# for date in avo_transformed_df['date']:\n",
    "#     date += timedelta(days=1)\n",
    "# avo_transformed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_columns = [\"Date\", \"Banana Price per Pound\", \"Percent Change\"]\n",
    "bananas_df = banana_prices_df[ban_columns].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "bananas_df = bananas_df.rename(columns={\"Date\": \"date\",\n",
    "                                        \"Banana Price per Pound\": \"price_per_pound\",\n",
    "                                        \"Percent Change\": \"percent_change\",\n",
    "                                        })\n",
    "\n",
    "# bananas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDweather_df = initSDweather_df[[\"dt\", \"temp\", \"rain_1h\", \"rain_3h\", \"snow_1h\", \"snow_3h\", \"weather_description\"]]\n",
    "# SDweather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-782439be5ac4>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SDweather_df[\"dt\"] = pd.to_datetime(SDweather_df[\"dt\"], unit=\"s\")\n"
     ]
    }
   ],
   "source": [
    "SDweather_df[\"dt\"] = pd.to_datetime(SDweather_df[\"dt\"], unit=\"s\")\n",
    "# SDweather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-b030127bf400>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SDweather_df['date'] = [d.date() for d in SDweather_df['dt']]\n",
      "<ipython-input-22-b030127bf400>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SDweather_df['time'] = [d.time() for d in SDweather_df['dt']]\n"
     ]
    }
   ],
   "source": [
    "SDweather_df['date'] = [d.date() for d in SDweather_df['dt']]\n",
    "SDweather_df['time'] = [d.time() for d in SDweather_df['dt']]\n",
    "# SDweather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_columns = [\"date\", \"temp\", \"rain_1h\", \"rain_3h\", \"snow_1h\", \"snow_3h\", \"weather_description\"]\n",
    "sanDiegoWeather_df = SDweather_df[weather_columns].copy()\n",
    "# sanDiegoWeather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avo_transformed_df = avo_transformed_df.dropna()\n",
    "gas_transformed_df = gas_transformed_df.dropna()\n",
    "tot_transport_df = tot_transport_df.dropna()\n",
    "avo_transport_df = avo_transport_df.dropna()\n",
    "bananas_df = bananas_df.dropna()\n",
    "sanDiegoWeather_df = sanDiegoWeather_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-666a02a58d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# price_transportation_merge = avo_transport_df.merge(avo_transformed_df, how='left', on='date')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavo_transport_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavo_transformed_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'merge' is not defined"
     ]
    }
   ],
   "source": [
    "# price_transportation_merge = avo_transport_df.merge(avo_transformed_df, how='left', on='date')\n",
    "merge(avo_transport_df, avo_transformed_df, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 1) (774, 1)\n"
     ]
    }
   ],
   "source": [
    "X = price_transportation_merge['avg_rate_per_mile_ratio'].values.reshape(-1, 1)\n",
    "y = price_transportation_merge[\"average_price\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [774, 169]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7f76aa5f57e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Fit (Train) our model to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [774, 169]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit (Train) our model to the data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
